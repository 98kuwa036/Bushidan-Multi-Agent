# Bushidan Multi-Agent System v9.1 - Enhanced Dependencies  
# 4-Tier Hybrid Architecture with DSPy Integration

# Core dependencies (required)
httpx>=0.24.0
aiohttp>=3.8.0               # Enhanced async HTTP for web search
python-dotenv>=1.0.0
pydantic>=2.0.0
pyyaml>=6.0
asyncio-throttle>=1.0.2      # Rate limiting for API calls

# AI Model APIs (required for 4-tier architecture)
anthropic>=0.34.0             # Claude 3.5 Sonnet + Opus 4 for Shogun (将軍) - Updated for Opus support
google-generativeai>=0.3.0    # Gemini 2.0 Flash for Karo (家老)
groq>=0.4.0                  # Alternative Karo for speed-critical tasks
litellm>=1.0.0               # OpenAI-compatible API for Taisho (大将)

# DSPy integration (recommended)
dspy>=2.0.0                  # Prompt optimization and translation layer

# Enhanced web search and scraping ⭐⭐⭐⭐⭐
tavily-python>=0.3.0          # Precise URL discovery
playwright>=1.40.0            # Targeted content extraction (1,000-2,000 chars)

# Optional integrations
slack-sdk>=3.21.0             # Slack Bot interface
notion-client>=2.0.0          # Long-term memory (Notion)

# Development dependencies (dev only)
pytest>=7.4.0
pytest-asyncio>=0.21.0
black>=23.0.0
ruff>=0.1.0
mypy>=1.5.0

# System utilities
pathlib2>=2.3.7

# Enhanced installation notes for v9.1:
# 
# Minimal (Shogun + Karo only):
#   pip install anthropic google-generativeai httpx python-dotenv pydantic
#
# Recommended (4-tier with web search ⭐):
#   pip install -r requirements.txt
#   playwright install chromium
#
# Full development setup:
#   pip install -r requirements.txt
#   playwright install chromium
#   pip install -e .[dev]
#
# Local Taisho setup (Qwen3-Coder-30B-A3B):
#   # Install Ollama
#   curl -fsSL https://ollama.com/install.sh | sh
#   
#   # Pull Qwen3-Coder (Q4_K_M quantization for 24GB systems)
#   ollama pull qwen3-coder-30b-a3b:q4_k_m
#   
#   # Start LiteLLM proxy
#   litellm --config config/litellm_config.yaml
#
# Performance notes:
#   - Qwen3-Coder MoE: ~24 tok/s CPU inference (practical)
#   - Q4_K_M quantization: ~18GB VRAM usage
#   - DSPy optimization: 30-40% better prompt effectiveness
#   - Context compression: Keeps requests under 4k tokens
#
# v9.1 eliminates v8.1 heavy dependencies (saves ~2GB):
#   ❌ Docker, Qdrant, SQLAlchemy, PyTorch, FastAPI
#   ✅ DSPy, Groq, enhanced async libraries